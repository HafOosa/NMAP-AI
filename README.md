# NMAP-AI : GÃ©nÃ©rateur de Commandes Nmap BasÃ© sur l'IA

## Table des matiÃ¨res

1. [Introduction](#introduction)
2. [Objectifs](#objectifs)
3. [RÃ©partition des TÃ¢ches](#rÃ©partition-des-tÃ¢ches)
4. [Technologies UtilisÃ©es](#technologies-utilisÃ©es)
5. [Modules et FonctionnalitÃ©s](#modules-et-fonctionnalitÃ©s)
   - [Personne 1 : Imane Allioui](#personne-1-imane-allioui)
   - [Personne 2 : Chaimae Ababri](#personne-2-chaimae-ababri)
   - [Personne 3 : Rami Hala](#personne-3-rami-hala)
   - [Personne 4 : Habib Samia](#personne-4-habib-samia)
   - [Personne 5 : El Guallaf Hafssa](#personne-5-el-guallaf-hafssa)
6. [Installation et Utilisation](#installation-et-utilisation)
7. [RÃ©sultats et Ã‰valuation](#rÃ©sultats-et-Ã©valuation)
8. [Avenir et AmÃ©liorations](#avenir-et-amÃ©liorations)

## Introduction

Le projet **NMAP-AI** a pour objectif de simplifier lâ€™utilisation de **Nmap**, un outil de sÃ©curitÃ© rÃ©seau, en permettant de gÃ©nÃ©rer automatiquement des commandes **Nmap** Ã  partir de requÃªtes en **langage naturel**. GrÃ¢ce Ã  lâ€™intelligence artificielle et aux modÃ¨les de machine learning, ce projet transforme des requÃªtes complexes en commandes exploitables pour des analyses de sÃ©curitÃ©.

Les diffÃ©rents types de requÃªtes sont classÃ©s en trois niveaux de complexitÃ© : **EASY**, **MEDIUM** et **HARD**, permettant ainsi une gÃ©nÃ©ration dynamique et optimisÃ©e des commandes.

## Objectifs

- **Comprendre le besoin** : Convertir des requÃªtes en langage naturel en commandes Nmap adaptÃ©es.
- **GÃ©nÃ©rer des commandes Nmap** : CrÃ©er un modÃ¨le capable de prÃ©dire la complexitÃ© des requÃªtes et de gÃ©nÃ©rer les commandes correspondantes.
- **Optimisation** : AmÃ©liorer la gestion des requÃªtes complexes en utilisant des modÃ¨les dâ€™IA adaptÃ©s (medium et hard).

## RÃ©partition des TÃ¢ches

| Personne | RÃ´le & ResponsabilitÃ©                                                                                  |
|----------|--------------------------------------------------------------------------------------------------------|
| **Personne 1** | **Imane Allioui** : Construction et gestion du **Knowledge Graph** pour enrichir les donnÃ©es de recherche et de gÃ©nÃ©ration de commandes. |
| **Personne 2** | **Chaimae Ababri** : PrÃ©paration des donnÃ©es, **fine-tuning des modÃ¨les** (Phi-4 et Diffusion) pour la gestion des requÃªtes **MEDIUM** et **HARD**. |
| **Personne 3** | **Rami Hala** : **Classification des requÃªtes** (EASY, MEDIUM, HARD) et routage vers les modÃ¨les appropriÃ©s. |
| **Personne 4** | **Habib Samia** : DÃ©veloppement de l'agent **RAG** pour les requÃªtes **EASY** et correction automatique des erreurs de requÃªtes. |
| **Personne 5** | **El Guallaf Hafssa** : Validation des commandes gÃ©nÃ©rÃ©es et prise de dÃ©cision finale sur l'exÃ©cution des commandes. |

## Technologies UtilisÃ©es

- **Python** : Langage principal pour le dÃ©veloppement des modÃ¨les et du systÃ¨me.
- **PyTorch** : Framework utilisÃ© pour le fine-tuning des modÃ¨les **Phi-4** et **Diffusion**.
- **Hugging Face Transformers** : Utilisation des modÃ¨les de type T5 pour la gÃ©nÃ©ration de commandes Nmap.
- **Spacy** : Pour le prÃ©traitement des donnÃ©es textuelles et l'extraction de caractÃ©ristiques.
- **Git LFS** : Gestion des fichiers volumineux (comme les bases de donnÃ©es) dans le dÃ©pÃ´t Git.

## Modules et FonctionnalitÃ©s

### Personne 1 : Imane Allioui

- **Gestion du Knowledge Graph** : Enrichissement des donnÃ©es avec des relations entre services et ports.
- **RequÃªtes faciles (EASY)** : Utilisation de l'agent **RAG** pour traiter les requÃªtes simples de type **EASY**.

### Personne 2 : Chaimae Ababri

En tant que **Personne 2**, vous avez travaillÃ© sur **la gestion des requÃªtes complexes (MEDIUM et HARD)**, en fine-tunant des modÃ¨les de gÃ©nÃ©ration de commandes et en crÃ©ant des scripts d'infÃ©rence.

#### Ã‰tapes dÃ©taillÃ©es de votre tÃ¢che :

1. **PrÃ©paration du Dataset** :
   - **Enrichissement du dataset** : Vous avez crÃ©Ã© et enrichi un dataset pour les requÃªtes **EASY**, **MEDIUM**, et **HARD**. Vous avez intÃ©grÃ© des services comme **SSH**, **FTP**, **HTTP**, etc., et associÃ© chaque service Ã  son port respectif.
   - **Paraphrasing des requÃªtes** : Vous avez augmentÃ© le dataset en crÃ©ant des paraphrases des requÃªtes pour rendre le modÃ¨le plus flexible face aux variations des instructions. Par exemple, "Scan port 22" a Ã©tÃ© reformulÃ© sous diffÃ©rentes formes pour couvrir des variantes de syntaxe et de style.
   - **Exemples de donnÃ©es** :
     ```json
     {
       "instruction": "Scan port 22 on 192.168.1.0/24",
       "input": "",
       "output": "nmap -p 22 192.168.1.0/24"
     }
     ```
     Ces exemples ont Ã©tÃ© utilisÃ©s pour entraÃ®ner les modÃ¨les sur des requÃªtes de **niveau MEDIUM**.

2. **Fine-Tuning des ModÃ¨les** :
   - **ModÃ¨le Phi-4 pour les requÃªtes MEDIUM** : Vous avez fine-tunÃ© un modÃ¨le **T5-base** (Phi-4) pour gÃ©rer les requÃªtes **MEDIUM** nÃ©cessitant une dÃ©tection de services et une analyse de vulnÃ©rabilitÃ©s. Le modÃ¨le a Ã©tÃ© entraÃ®nÃ© pour comprendre des instructions complexes et gÃ©nÃ©rer des commandes Nmap adaptÃ©es.
   - **Exemple de fine-tuning du modÃ¨le** :
     ```python
     from transformers import T5ForConditionalGeneration, T5Tokenizer
     from transformers import Trainer, TrainingArguments
     from datasets import load_dataset

     model = T5ForConditionalGeneration.from_pretrained("t5-base")
     tokenizer = T5Tokenizer.from_pretrained("t5-base")

     # Charger et prÃ©parer le dataset
     train_dataset = load_dataset("data/t5_balanced_train.json")
     val_dataset = load_dataset("data/t5_balanced_val.json")

     training_args = TrainingArguments(
         output_dir="./results",
         per_device_train_batch_size=16,
         per_device_eval_batch_size=16,
         num_train_epochs=3,
         logging_dir='./logs',
     )

     trainer = Trainer(
         model=model,
         args=training_args,
         train_dataset=train_dataset,
         eval_dataset=val_dataset,
         tokenizer=tokenizer,
     )

     trainer.train()
     ```

   - **ModÃ¨le Diffusion pour les requÃªtes HARD** : Pour les requÃªtes complexes de **niveau HARD**, vous avez utilisÃ© un modÃ¨le **Diffusion**. Ce modÃ¨le a Ã©tÃ© fine-tunÃ© pour traiter des scans complexes, comme les scans furtifs, les Ã©vasions de pare-feu, et les scans avancÃ©s.
     ```python
     from transformers import T5ForConditionalGeneration, T5Tokenizer
     from peft import PeftModel
     import torch

     model = T5ForConditionalGeneration.from_pretrained("t5-base")
     model = model.to("cuda" if torch.cuda.is_available() else "cpu")
     tokenizer = T5Tokenizer.from_pretrained("t5-base")

     peft_model = PeftModel.from_pretrained(model, "path/to/hard_model")

     instruction = "Scan with evasion using decoys on 192.168.1.0/24"
     inputs = tokenizer(instruction, return_tensors="pt")
     outputs = peft_model.generate(**inputs)

     generated_command = tokenizer.decode(outputs[0], skip_special_tokens=True)
     print(f"Commande gÃ©nÃ©rÃ©e : {generated_command}")
     ```

3. **Ã‰valuation des ModÃ¨les** :
   - Vous avez Ã©valuÃ© les modÃ¨les sur un **dataset de test** pour mesurer leur performance dans la gÃ©nÃ©ration de commandes Nmap pour les requÃªtes **MEDIUM** et **HARD**.
   - **RÃ©sultats** : Les modÃ¨les ont atteint une prÃ©cision de **85-92%** pour les requÃªtes **MEDIUM** et de **70-80%** pour les requÃªtes **HARD**, ce qui montre une bonne capacitÃ© du modÃ¨le Ã  gÃ©rer des requÃªtes complexes.

4. **CrÃ©ation des Scripts d'InfÃ©rence** :
   - Vous avez crÃ©Ã© des scripts permettant d'utiliser les modÃ¨les fine-tunÃ©s pour gÃ©nÃ©rer des commandes Nmap en rÃ©ponse Ã  des requÃªtes en langage naturel. Voici un exemple de votre code pour l'infÃ©rence :
     ```python
     instruction = "Scan all ports on 192.168.1.0/24"
     generated_command = model.generate(instruction)
     print(f"Commande gÃ©nÃ©rÃ©e : {generated_command}")
     ```

### Personne 3 : Rami Hala

                               Person 3 Module â€” Nmap Complexity Classification

ğŸ“Œ Project Context

This module represents the work of Person 3 in the collaborative NMAP-AI project.
It acts as the decision core of the system, responsible for understanding Nmap natural language queries and estimating their complexity level in order to enable intelligent routing to the appropriate AI engine.

ğŸ¯ Module Objective

â¦ Given a user Nmap request expressed in natural language, the module must:
â¦ Analyze the query using NLP techniques
â¦ Extract technical and semantic features
â¦ Predict a complexity level
â¦ Provide a clear, explainable decision

ğŸšï¸ Complexity Levels

| Level     | Meaning                 | Routing              |
| --------- | ----------------------- | -------------------- |
| ğŸŸ¢ EASY   | Simple, low-risk scan   | RAG (Person 1)       |
| ğŸŸ¡ MEDIUM | Standard technical scan | Phi-4 (Person 2)     |
| ğŸ”´ HARD   | Stealth / evasion scan  | Diffusion (Person 2) |

ğŸ§  Global Approach

The module is based on a hybrid architecture combining:

â¦ ğŸ§© Advanced NLP (spaCy)
â¦ ğŸŒ² Machine Learning (Random Forest)
â¦ ğŸ§  Expert business rules
â¦ ğŸ•¸ï¸ Knowledge Graph enrichment (Neo4j â€“ Person 1)

This design ensures:

â¦ Robust generalization (ML)
â¦ Precise handling of critical edge cases (rules)
â¦ Semantic understanding of Nmap concepts (KG)

ğŸ—ï¸ Module Architecture

src/
â”œâ”€â”€ extract_features.py # NLP feature extraction
â”œâ”€â”€ enrich_with_kg.py # Neo4j knowledge graph enrichment
â”œâ”€â”€ train_classifier.py # ML model training
â”œâ”€â”€ classifier.py # Prediction + business rules
â”œâ”€â”€ router.py # Final intelligent routing
models/
â”œâ”€â”€ complexity_classifier.pkl # Trained ML model
data/
â”œâ”€â”€ dataset_fusionne.csv # Final training dataset
screenshots/

âœ… Implemented Features

1ï¸âƒ£ Advanced NLP Feature Extraction

The file extract_features.py converts a natural language query into a rich numerical vector (>25 features), including:
â¦ Linguistic statistics (tokens, POS, named entities)
â¦ IP address, network range and port detection
â¦ Keyword detection per complexity level
â¦ Nmap options (UDP, OS detection, scripts, timing)
â¦ Single-port detection
â¦ Weighted complexity score

2ï¸âƒ£ Knowledge Graph Enrichment (Neo4j â€“ Person 1)

The module enrich_with_kg.py enriches features by querying the Knowledge Graph.

Neo4j labels used

â¦ Option
â¦ ScanType
â¦ Port
â¦ Script

Added features

â¦ Number of recognized options
â¦ Number of associated relationships
â¦ Average usage frequency
â¦ Script risk indicators

ğŸ”’ Fault tolerance: if Neo4j is unavailable â†’ default values are applied.

3ï¸âƒ£ Machine Learning Classification (Random Forest)

â¦ Algorithm: RandomForestClassifier
â¦ Input: numerical feature vector (NLP + KG)
â¦ Classes: EASY / MEDIUM / HARD
â¦ Dataset: merged multi-source datasets (CSV + JSON)

The trained model is saved as:

models/complexity_classifier.pkl

![Training Accuracy](screenshots/training_accuracy.png)

4ï¸âƒ£ Post-Prediction Business Rules

To handle linguistic ambiguities and edge cases, expert rules are applied after ML prediction:

â¦ Single port scan â†’ EASY
â¦ Standard ports without advanced options â†’ EASY
â¦ OS detection on a network â†’ at least MEDIUM
â¦ Stealth / evasion techniques (fragmentation, decoy, spoofing) â†’ HARD

5ï¸âƒ£ Final Classifier (Interactive Mode)

Run:

â¦ python src/classifier.py

Example:

Enter Nmap query > Stealth scan with fragmentation and decoy
â†’ Detected complexity: HARD

![Classifier Test](screenshots/classifier_test.png)

6ï¸âƒ£ Intelligent Router

The router.py module provides:

â¦ Complexity prediction
â¦ Confidence score
â¦ Human-readable explanation
â¦ Clear routing recommendation

![Router Output](screenshots/router_output.png)

ğŸŒ REST API â€” FastAPI (Production Ready)

The module exposes a REST API using FastAPI, allowing external systems (frontend, orchestrator, or other agents) to query the Nmap complexity classifier in real time.

ğŸ“„ api.py

The API wraps the routing logic and provides:

â¦ Input validation
â¦ Error handling
â¦ Confidence scores
â¦ Explainable predictions
â¦ CORS support (for frontend / Postman testing)

ğŸš€ Available Endpoints

ğŸ”¹ Health Check
GET /

Response

{
"message": "NMAP-AI Router prÃªt ! POST /predict avec {'query': 'votre phrase'}"
}

ğŸ”¹ Predict Nmap Complexity
POST /predict

Request Body

{
"query": "Scan SYN furtif avec fragmentation sur 192.168.1.0/24"
}

Response

{
"predicted_complexity": "HARD",
"confidence": 0.973,
"all_probabilities": {
"EASY": 0.013,
"MEDIUM": 0.013,
"HARD": 0.973
},
"explanation": "â€¢ Fragmentation de paquets dÃ©tectÃ©e (-f)\nâ†’ **Classe prÃ©dite : HARD**"
}

ğŸ›¡ Error Handling

â¦ Empty query â†’ 400 Bad Request
â¦ Non-Nmap request â†’ 400 Bad Request
â¦ Internal error â†’ 500 Internal Server Error (with server traceback)

â–¶ï¸ Run the API

â¦ python src/api.py

Server runs on:

http://localhost:8002

Interactive Swagger UI:

http://localhost:8002/docs

![FastAPI Swagger](screenshots/api_swagger.png)
![API Prediction](screenshots/api_predict.png)

ğŸ“Š Results and Validation

Significant reduction of false HARD classifications

Proper handling of edge cases

Fully explainable decisions

System ready for global integration

ğŸ¤ Integration with Other Team Members

| Person   | Interaction                  |
| -------- | ---------------------------- |
| Person 1 | Knowledge Graph (Neo4j)      |
| Person 2 | Routing to Phi-4 / Diffusion |
| Person 4 | System-level integration     |

ğŸ Module Status

âœ… Development: COMPLETED
âœ… Testing: VALIDATED
âœ… Integration: READY


### Personne 4 : Habib Samia

- **DÃ©veloppement de l'Agent RAG** : Traitement des requÃªtes **EASY** en utilisant l'agent **RAG** pour gÃ©nÃ©rer des commandes simples de Nmap.
- **Correction automatique** des erreurs dans les requÃªtes et ajustements en fonction des critÃ¨res.

### Personne 5 : El Guallaf Hafssa

- **Validation des Commandes GÃ©nÃ©rÃ©es** : VÃ©rification de la prÃ©cision des commandes gÃ©nÃ©rÃ©es par les modÃ¨les pour s'assurer de leur validitÃ© avant l'exÃ©cution.
- **Prise de dÃ©cision** sur l'exÃ©cution des commandes en fonction du type de requÃªte et du contexte de sÃ©curitÃ©.

## Installation et Utilisation

### PrÃ©requis

- Python 3.8+ installÃ©
- Pip pour gÃ©rer les packages

### Installation des dÃ©pendances

```bash
git clone https://github.com/HafOosa/NMAP-AI.git
cd NMAP-AI
pip install -r requirements.txt
